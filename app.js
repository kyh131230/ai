const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const statusText = document.getElementById("status");

const modelInputSize = 640;
const modelPath = "./model/yolov8n.onnx";

let session = null;

async function setupCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: "environment" },
    audio: false
  });
  video.srcObject = stream;
  return new Promise((resolve) => {
    video.onloadedmetadata = () => {
      video.play();
      resolve();
    };
  });
}

function preprocess() {
  const tempCanvas = document.createElement("canvas");
  tempCanvas.width = modelInputSize;
  tempCanvas.height = modelInputSize;
  const tempCtx = tempCanvas.getContext("2d");

  // ðŸ“¸ video â†’ 640x640 ì¶”ì¶œ
  tempCtx.drawImage(video, 0, 0, modelInputSize, modelInputSize);
  const { data: resizedData } = tempCtx.getImageData(0, 0, modelInputSize, modelInputSize);

  const floatData = new Float32Array(3 * modelInputSize * modelInputSize);
  for (let i = 0; i < modelInputSize * modelInputSize; i++) {
    floatData[i] = resizedData[i * 4] / 255;
    floatData[i + modelInputSize * modelInputSize] = resizedData[i * 4 + 1] / 255;
    floatData[i + 2 * modelInputSize * modelInputSize] = resizedData[i * 4 + 2] / 255;
  }

  return new ort.Tensor("float32", floatData, [1, 3, modelInputSize, modelInputSize]);
}

async function detectFrame() {
  if (!session) return;

  const inputTensor = preprocess();
  const feeds = { images: inputTensor };
  const results = await session.run(feeds);
  const output = results[session.outputNames[0]].data;

  // ðŸ“º ì›ë³¸ ì˜ìƒ ì¶œë ¥
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  // ðŸ“¦ ë°•ìŠ¤ ì¶œë ¥
  drawBoxes(output, ctx, canvas.width, canvas.height);

  requestAnimationFrame(detectFrame);
}

async function main() {
  statusText.textContent = "ðŸ“¸ ì¹´ë©”ë¼ ì—°ê²° ì¤‘...";
  await setupCamera();

  statusText.textContent = "ðŸ“¦ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...";
  session = await ort.InferenceSession.create(modelPath);

  statusText.textContent = "âœ… ìž‘ë™ ì¤‘";
  detectFrame();
}

main();
