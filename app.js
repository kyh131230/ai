const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const status = document.getElementById('status');

const modelInputSize = 640;
const modelPath = './model/yolov8n.onnx'; // í•„ìš”í•œ ê²½ìš° ì ˆëŒ€ê²½ë¡œë¡œ ë³€ê²½

let session = null;

async function setupCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: 'environment' },
    audio: false
  });
  video.srcObject = stream;
  return new Promise((resolve) => {
    video.onloadedmetadata = () => {
      video.play();
      resolve();
    };
  });
}

function preprocess() {
  const tempCanvas = document.createElement("canvas");
  tempCanvas.width = modelInputSize;
  tempCanvas.height = modelInputSize;
  const tempCtx = tempCanvas.getContext("2d");

  tempCtx.drawImage(video, 0, 0, modelInputSize, modelInputSize);
  const { data: resizedData } = tempCtx.getImageData(0, 0, modelInputSize, modelInputSize);

  const floatData = new Float32Array(3 * modelInputSize * modelInputSize);
  for (let i = 0; i < modelInputSize * modelInputSize; i++) {
    floatData[i] = resizedData[i * 4] / 255;                           // R
    floatData[i + modelInputSize * modelInputSize] = resizedData[i * 4 + 1] / 255; // G
    floatData[i + 2 * modelInputSize * modelInputSize] = resizedData[i * 4 + 2] / 255; // B
  }

  return new ort.Tensor('float32', floatData, [1, 3, modelInputSize, modelInputSize]);
}

async function detectFrame() {
  if (!session) return;

  const inputTensor = preprocess();
  const feeds = { images: inputTensor };

  const results = await session.run(feeds);
  const output = results[session.outputNames[0]].data;

  // ì›ë³¸ ì˜ìƒ ë‹¤ì‹œ ê·¸ë¦¼
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  // ê°ì²´ ê°ì§€ ê²°ê³¼ í‘œì‹œ
  drawBoxes(output, ctx, canvas.width, canvas.height);

  requestAnimationFrame(detectFrame);
}

async function main() {
  status.textContent = "ðŸ“¸ ì¹´ë©”ë¼ ì„¤ì • ì¤‘...";
  await setupCamera();

  status.textContent = "ðŸ“¦ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...";
  session = await ort.InferenceSession.create(modelPath);

  status.textContent = "âœ… ìž‘ë™ ì¤‘";
  detectFrame();
}

main();