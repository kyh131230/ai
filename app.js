const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const status = document.getElementById('status');

let modelSession = null;
const modelInputSize = 640;
const modelPath = './model/yolov8n.onnx';

function log(msg, color = 'green') {
  status.innerText = msg;
  status.style.color = color;
}

async function initCamera() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: 'environment' },
      audio: false
    });
    video.srcObject = stream;

    // ë©”íƒ€ë°ì´í„°ê°€ ì™„ì „íˆ ë¡œë“œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
    await new Promise(resolve => {
      video.onloadedmetadata = () => {
        video.play();
        resolve();
      };
    });

    // ì •í™•í•œ video í¬ê¸° ì ìš©
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    log("âœ… ì¹´ë©”ë¼ ì‹œì‘ë¨");
  } catch (err) {
    log("âŒ ì¹´ë©”ë¼ ì ‘ê·¼ ì˜¤ë¥˜: " + err.message, 'red');
  }
}

async function loadModel() {
  try {
    log("ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...");
    modelSession = await ort.InferenceSession.create(modelPath);
    log("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ");
  } catch (err) {
    log("âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: " + err.message, 'red');
  }
}

function preprocess() {
  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
  const { data } = imageData;

  const floatData = new Float32Array(3 * modelInputSize * modelInputSize);

  // Resize: í˜„ì¬ ì˜ìƒ í¬ê¸°ë¥¼ 640x640ì— ë§ì¶° ì„ì‹œ ìº”ë²„ìŠ¤ì— resize
  const tempCanvas = document.createElement("canvas");
  tempCanvas.width = modelInputSize;
  tempCanvas.height = modelInputSize;
  const tempCtx = tempCanvas.getContext("2d");
  tempCtx.drawImage(canvas, 0, 0, modelInputSize, modelInputSize);
  const resizedData = tempCtx.getImageData(0, 0, modelInputSize, modelInputSize).data;

  for (let i = 0; i < modelInputSize * modelInputSize; i++) {
    floatData[i] = resizedData[i * 4] / 255; // R
    floatData[i + modelInputSize * modelInputSize] = resizedData[i * 4 + 1] / 255; // G
    floatData[i + 2 * modelInputSize * modelInputSize] = resizedData[i * 4 + 2] / 255; // B
  }

  return new ort.Tensor('float32', floatData, [1, 3, modelInputSize, modelInputSize]);
}


document.getElementById('captureBtn').addEventListener('click', async () => {
  if (!modelSession) {
    log("âŒ ëª¨ë¸ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", 'red');
    return;
  }

  // 1ï¸âƒ£ ì‹¤ì œ ì˜ìƒ í”„ë ˆì„ ìº¡ì²˜ í™•ì¸ìš© ë¡œê·¸
  console.log("ğŸ“¸ video.readyState =", video.readyState);  // 0 ~ 4
  console.log("ğŸï¸ video.videoWidth =", video.videoWidth);
  if (video.readyState < 2) {
  log("âš ï¸ ë¹„ë””ì˜¤ í”„ë ˆì„ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", 'orange');
  return;
  }
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

// ë””ë²„ê¹…ìš©: ì²« ë²ˆì§¸ í”½ì…€ì´ ì „ë¶€ 255ë¼ë©´ í°ìƒ‰ì„
  const imgData = ctx.getImageData(0, 0, 1, 1);
  const [r, g, b] = imgData.data;
  console.log("ğŸ¨ ì²« í”½ì…€:", r, g, b);

  if (r === 255 && g === 255 && b === 255) {
    log("âš ï¸ ì¹´ë©”ë¼ì—ì„œ ì˜ìƒì´ ì•ˆ ì°íˆê³  í° í™”ë©´ì…ë‹ˆë‹¤", 'orange');
    return;
  }

  try {
    const input = preprocess();
    const outputMap = await modelSession.run({ images: input });
    const results = postprocess(outputMap, canvas.width, canvas.height);
    drawBoxes(results);
    log(`âœ… ${results.length}ê°œ ê°ì²´ ê°ì§€`);
  } catch (err) {
    log("âŒ ì¶”ë¡  ì˜¤ë¥˜: " + err.message, 'red');
  }
});

window.onload = async () => {
  await initCamera();
  await loadModel();
};
