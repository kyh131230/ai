const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const status = document.getElementById('status');

let modelSession = null;
const modelInputSize = 640;
const modelPath = './model/yolov8n.onnx';

function log(msg, color = 'green') {
  status.innerText = msg;
  status.style.color = color;
}

// ğŸ“¸ ì¹´ë©”ë¼ ì‹œì‘
async function initCamera() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode: 'environment' },
      audio: false
    });
    video.srcObject = stream;
    await video.play();

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    log("âœ… ì¹´ë©”ë¼ ì‹œì‘ë¨");
  } catch (err) {
    log("âŒ ì¹´ë©”ë¼ ì ‘ê·¼ ì˜¤ë¥˜: " + err.message, 'red');
  }
}

// ğŸ¤– ëª¨ë¸ ë¡œë”©
async function loadModel() {
  try {
    log("ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...");
    modelSession = await ort.InferenceSession.create(modelPath);
    log("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ");
  } catch (err) {
    log("âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: " + err.message, 'red');
  }
}

// ğŸ§  ì „ì²˜ë¦¬
function preprocess() {
  const tempCanvas = document.createElement('canvas');
  tempCanvas.width = modelInputSize;
  tempCanvas.height = modelInputSize;
  const tempCtx = tempCanvas.getContext('2d');
  tempCtx.drawImage(video, 0, 0, modelInputSize, modelInputSize);

  const imageData = tempCtx.getImageData(0, 0, modelInputSize, modelInputSize);
  const { data } = imageData;

  const floatData = new Float32Array(modelInputSize * modelInputSize * 3);
  for (let i = 0; i < modelInputSize * modelInputSize; i++) {
    floatData[i] = data[i * 4] / 255;
    floatData[i + modelInputSize * modelInputSize] = data[i * 4 + 1] / 255;
    floatData[i + 2 * modelInputSize * modelInputSize] = data[i * 4 + 2] / 255;
  }

  return new ort.Tensor('float32', floatData, [1, 3, modelInputSize, modelInputSize]);
}

// ğŸ“¦ í›„ì²˜ë¦¬ (ìƒëµ ê°€ëŠ¥. ì•ì„œ ì‘ì„±í•œ postprocess, drawBoxes í•¨ìˆ˜ ì‚¬ìš©)

// ğŸ“¸ ë²„íŠ¼ í´ë¦­ â†’ ë¶„ì„ ì‹¤í–‰
document.getElementById('captureBtn').addEventListener('click', async () => {
  if (!modelSession) {
    log("âŒ ëª¨ë¸ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", 'red');
    return;
  }

  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
  try {
    const input = preprocess();
    const outputMap = await modelSession.run({ images: input });
    const results = postprocess(outputMap, canvas.width, canvas.height);
    drawBoxes(results);
    log(`âœ… ${results.length}ê°œ ê°ì²´ ê°ì§€`);
  } catch (err) {
    log("âŒ ì¶”ë¡  ì˜¤ë¥˜: " + err.message, 'red');
  }
});

// âœ… ì „ì²´ ì´ˆê¸°í™”
window.onload = async () => {
  await initCamera();
  await loadModel();
};